% !TEX root = ../main.tex

\begin{digest}

Randomized Control Trials (RCTs), also known in practice as A/B testing, are pivotal in the advancement of medical and technological research. The progression of technology, the ubiquity of online interactions, and the accessibility to large-scale datasets have empowered tech companies to deploy RCTs in expansive online settings. This application of RCTs has facilitated data-driven decision-making, accelerating the deployment and commercial validation of innovative solutions, substantially improving user experiences, and enhancing corporate profitability.

In RCTs, the primary metric targeted for change through specific interventions, such as mortality rates in clinical trials or click-through rates in digital marketing studies, is referred to as the outcome variable or response. Other variables within the model, which serve as explanatory factors, are termed covariates or explanatory variables. Typically, the study of interest is the association of one or more covariates with the response, so it is necessary to have to control for the remaining covariates that are not of primary interest. We also refer to covariates of interest as treatment variables, such as treatment regimens, disease types, recommendation algorithms, and so on.

RCTs typically compare a proposed treatment method against a standard or existing approach, with the two approaches categorized as the "treatment" and "control" groups. In cases where no broadly accepted standard treatment exists, a placebo is used in the control group, known as a blind trial. Blind trials mitigate subjective biases and placebo effects from patients and healthcare providers, ensuring more reliable data.

Beyond the variables within the model, there are extraneous factors that could potentially influence outcomes, such as instrumental testing errors and environmental shifts. It is impractical to control for all variables that may impact the response variable. By nature, unobserved variables cannot be included in the model due to their lack of observability, and overcomplicating the model with too many variables can diminish the experimental power. RCTs, through the amalgamation of large samples and randomization, significantly prevent the improper influence of these unobserved variables.

In the realm of experimental research, randomization is a fundamental technique implemented to balance covariates between treatment groups. While this method is effective in creating equilibrium on average, disparities in covariate distributions may still arise within any individual experiment. Rerandomization offers a straightforward and intuitive approach to ameliorate imbalances in covariates within the context of randomized experiments. 

The Rerandomization experimental design consists of these steps:
\begin{enumerate}
    \item collect covariate data.
    \item determining an equilibrium criterion and accepting this randomization when it meets this criterion.
    \item  randomly assign the sample to the treatment and control groups.
    \item check whether the criterion is met: if it is met, go to step (5); otherwise, return to step (3).
    \item conduct separate experiments based on the results of the randomization in step 3.
    \item  analyze the results.
\end{enumerate}

To operationalize rerandomization, it is imperative to define a set of criteria that determine the acceptability of the randomization outcome. These criteria are essential to ensure the unbiasedness of the experiment, necessitating a balanced allocation of participants across both treatment and control groups. This article demonstrates that given a covariate matrix, the Mahalanobis distance between the treatment and control groups obeys a chi-square distribution with degrees of freedom in the dimension of the covariate matrix in the case of large samples. If the criterion adopted is to rerandomize whenever the Mahalanobis distance exceeds a certain threshold, then rerandomization reduces the variance of the difference in means between the two groups, and when the covariates are correlated with the outcome, rerandomization increases the precision of the treatment effect estimates. When faced with high-dimensional data, rerandomization using the Mahalanobis distance loses randomness. To address the above issues, experimental designers may consider using other distances to construct acceptable randomization criterion functions.

There are a number of common methods for generating a sequence of random assignments other than rerandomization. Depending on different scenarios and different experimental design requirements, the experimental designer often needs to adopt appropriate randomization schemes to achieve better experimental results and more effective causal inference.
In the next part, we will delve into the meticulous methodologies and critical considerations associated with the implementation of A/A testing, block randomization, and stratified randomization within experimental designs. Each of these techniques serves a unique purpose in enhancing the reliability and validity of experimental outcomes, particularly in the context of ensuring balanced distribution of covariates across treatment groups.

A/A testing and A/B testing share similarities in the experimental design process, with the sole distinction being that participants in both the experimental and control groups of an A/A test receive the same experimental influence A (typically a placebo or a widely current scheme), hence the designation A/A testing. If the grouping is relatively balanced, there should not be any significant pre-existing differences between the test and control groups. Consequently, if the results of an A/A test indicate significant imbalance between the groups, indicating an A/A test "failure," the experimental designers should approach the subsequent A/B test results with caution. Depending on the severity of the imbalance, options include disregarding the results, making statistical adjustments, or rerunning the experiment.

Block randomization further refines the process of group allocation by dividing the sample into predefined blocks of a specified size, within which participants are randomly assigned to groups. This technique is particularly versatile, applicable across varying sample sizes and capable of accommodating both balanced and unbalanced group sizes. Its primary advantage lies in its ability to mitigate biases introduced by sequence effects, ensuring that such biases do not skew the experimental outcomes. Through the systematic organization of participants into blocks, researchers can achieve a more uniform distribution of participants, enhancing the comparability of treatment effects.

Stratified randomization, on the other hand, introduces a layer of precision to the randomization process by incorporating predetermined stratification factors. Participants are segmented into distinct strata based on these factors, followed by random assignment within each stratum. This method ensures that the distribution of the stratification factors is evenly balanced across the treatment and control groups, thereby minimizing potential disparities that could affect the treatment outcomes. Stratified randomization is particularly beneficial in experiments where certain covariates are known to influence the response variable significantly, allowing for a more nuanced analysis of treatment effects.

Finally, we embark on a comprehensive exploration of the simulation of experimental outcomes through the generation of covariates  that adhere to a multivariate normal distribution. This simulation is further refined by employing a linear additive model alongside the results of group allocation to simulate the experimental outcomes. Subsequently, the chapter delves into the intricate experimental procedures and parameter configurations associated with various randomization techniques. These methodologies encompass rerandomization, A/A testing, block randomization, and stratified randomization, each contributing uniquely to the robustness and reliability of experimental outcomes. By setting specific parameters, this study undertakes an extensive simulation exercise, conducted over 10,000 iterations, to derive five sets of  results. This rigorous simulation process is instrumental in evaluating the efficacy and impact of different randomization strategies on the estimation of treatment effects.

The findings from these simulations reveal that all considered randomization methods maintain the unbiasedness of the  estimates. Notably, the implementation of rerandomization and stratified randomization significantly reduces the variance of estimated average treatment effects, thereby enhancing the precision of treatment effect estimates. In rerandomization experiments, the variance of the estimated average treatment effect increases with the rise of the acceptable randomization proportion, while the average computation time decreases. Consequently, experiment designers must strike a balance between the accuracy of the estimate and computational efficiency when employing rerandomization.

In summary, this study not only deepens the understanding of the covariate balance problem in randomized controlled experiments, but also provides a
series of practical solutions, and for experiment designers, by adopting these strategies for randomized trials, they can effectively improve the quality of randomized controlled experiments and ensure the accuracy and accuracy of research results.
For experiment designers, by adopting these randomized trial strategies, the quality of randomized controlled experiments can be effectively improved to ensure the accuracy and reliability.



\end{digest}
